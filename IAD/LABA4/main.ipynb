{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sench\\AppData\\Local\\Temp\\ipykernel_17040\\985841073.py:29: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n",
      "c:\\Users\\sench\\miniforge3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        76\n",
      "           1       0.38      1.00      0.55       117\n",
      "           2       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.38       305\n",
      "   macro avg       0.13      0.33      0.18       305\n",
      "weighted avg       0.15      0.38      0.21       305\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0  76   0]\n",
      " [  0 117   0]\n",
      " [  0 112   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sench\\miniforge3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sench\\miniforge3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sench\\miniforge3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data = pd.read_csv(\"Maternal Health Risk Data Set.csv\")\n",
    "label_encoder = LabelEncoder()\n",
    "data['RiskLevel'] = label_encoder.fit_transform(data['RiskLevel'])\n",
    "X = data.drop('RiskLevel', axis=1)\n",
    "y = data['RiskLevel']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "class RBM:\n",
    "    def __init__(self, n_visible, n_hidden):\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        self.weights = np.random.normal(0, 0.01, (n_visible, n_hidden))\n",
    "        self.visible_bias = np.zeros(n_visible)\n",
    "        self.hidden_bias = np.zeros(n_hidden)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sample_hidden(self, visible_data):\n",
    "        hidden_prob = self.sigmoid(np.dot(visible_data, self.weights) + self.hidden_bias)\n",
    "        hidden_sample = (hidden_prob > np.random.rand(len(visible_data), self.n_hidden)).astype(float)\n",
    "        return hidden_prob, hidden_sample\n",
    "    \n",
    "    def sample_visible(self, hidden_data):\n",
    "        visible_prob = self.sigmoid(np.dot(hidden_data, self.weights.T) + self.visible_bias)\n",
    "        visible_sample = (visible_prob > np.random.rand(len(hidden_data), self.n_visible)).astype(float)\n",
    "        return visible_prob, visible_sample\n",
    "    \n",
    "    def contrastive_divergence(self, visible_data, learning_rate=0.1, epochs=10):\n",
    "        for _ in range(epochs):\n",
    "            hidden_prob1, hidden_sample1 = self.sample_hidden(visible_data)\n",
    "            visible_prob, visible_sample = self.sample_visible(hidden_sample1)\n",
    "            hidden_prob2, hidden_sample2 = self.sample_hidden(visible_sample)\n",
    "            \n",
    "            positive_grad = np.dot(visible_data.T, hidden_prob1)\n",
    "            negative_grad = np.dot(visible_sample.T, hidden_prob2)\n",
    "            \n",
    "            self.weights += learning_rate * (positive_grad - negative_grad)\n",
    "            self.visible_bias += learning_rate * np.mean(visible_data - visible_sample, axis=0)\n",
    "            self.hidden_bias += learning_rate * np.mean(hidden_prob1 - hidden_prob2, axis=0)\n",
    "        \n",
    "        return self.weights, self.hidden_bias\n",
    "\n",
    "layer_sizes = [X_train.shape[1], 64, 32, 16, 8, 3]\n",
    "pretrained_weights = []\n",
    "pretrained_biases = []\n",
    "current_input = X_train\n",
    "for i in range(1, len(layer_sizes)):\n",
    "    rbm = RBM(layer_sizes[i-1], layer_sizes[i])\n",
    "    weights, bias = rbm.contrastive_divergence(current_input)\n",
    "    pretrained_weights.append(weights)\n",
    "    pretrained_biases.append(bias)\n",
    "    \n",
    "    _, current_input = rbm.sample_hidden(current_input)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.layers[0].set_weights([pretrained_weights[0], pretrained_biases[0]])\n",
    "model.layers[1].set_weights([pretrained_weights[1], pretrained_biases[1]])\n",
    "model.layers[2].set_weights([pretrained_weights[2], pretrained_biases[2]])\n",
    "model.layers[3].set_weights([pretrained_weights[3], pretrained_biases[3]])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=-1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sench\\miniforge3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        76\n",
      "           1       0.38      1.00      0.55       117\n",
      "           2       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.38       305\n",
      "   macro avg       0.13      0.33      0.18       305\n",
      "weighted avg       0.15      0.38      0.21       305\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0  76   0]\n",
      " [  0 117   0]\n",
      " [  0 112   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sench\\miniforge3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sench\\miniforge3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sench\\miniforge3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data = pd.read_csv(\"Maternal Health Risk Data Set.csv\")\n",
    "label_encoder = LabelEncoder()\n",
    "data['RiskLevel'] = label_encoder.fit_transform(data['RiskLevel'])\n",
    "X = data.drop('RiskLevel', axis=1)\n",
    "y = data['RiskLevel']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "layer_sizes = [X_train.shape[1], 64, 32, 16, 8, 3]\n",
    "pretrained_weights = []\n",
    "pretrained_biases = []\n",
    "\n",
    "current_input = X_train.copy()\n",
    "for i in range(1, len(layer_sizes)):\n",
    "    rbm = BernoulliRBM(\n",
    "        n_components=layer_sizes[i],\n",
    "        n_iter=100,\n",
    "        learning_rate=0.0003,\n",
    "        batch_size=64,\n",
    "        random_state=98\n",
    "    )\n",
    "    \n",
    "    binary_input = (current_input > current_input.mean()).astype(int)\n",
    "    \n",
    "    rbm.fit(current_input)\n",
    "    \n",
    "    pretrained_weights.append(rbm.components_.T)\n",
    "    pretrained_biases.append(rbm.intercept_hidden_)\n",
    "    \n",
    "    current_input = rbm.transform(binary_input)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.layers[0].set_weights([pretrained_weights[0], pretrained_biases[0]])\n",
    "model.layers[1].set_weights([pretrained_weights[1], pretrained_biases[1]])\n",
    "model.layers[2].set_weights([pretrained_weights[2], pretrained_biases[2]])\n",
    "model.layers[3].set_weights([pretrained_weights[3], pretrained_biases[3]])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=-1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
